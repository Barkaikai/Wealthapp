ice — below is a complete, copy-pasteable implementation that lets your app accept .tar.gz uploads, safely inspect and extract them on the server, and display/download the extracted contents from the frontend.

What you get:

Backend (Node + Express) routes:

POST /api/upload/targz — upload a .tar.gz and extract it into a safe per-upload folder

GET /api/upload/:id/list — get a JSON listing of extracted files

GET /api/upload/:id/file/* — download a single extracted file

GET /api/upload/:id/tree — return directory tree (optional)

Frontend React component:

Upload UI with drag/drop, progress, and listing of extracted files with download links

Safety & hardening:

File size limit

Path traversal protection (prevents ../ and absolute paths)

Extract into per-upload temp directory (UUID)

Optional virus/AV hooks recommended

No automatic execution of extracted files

Dependencies & install commands

Install (backend)

Run in your backend folder:

npm install express multer tar uuid fs-extra mime-types


multer — file upload handling

tar — extract .tar.gz safely

uuid — unique upload ids

fs-extra — nicer fs helpers

mime-types — serve correct content-types

Backend: routes/targzUpload.js

Copy this into your backend (adjust imports/style if you use ESM or TypeScript). This uses CommonJS (Node) style; if your project uses ESM, convert require to import.

// backend/routes/targzUpload.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs-extra');
const os = require('os');
const tar = require('tar'); // npm install tar
const { v4: uuidv4 } = require('uuid');
const mime = require('mime-types');

const router = express.Router();

// Multer: store upload to temp location first
const upload = multer({
  dest: path.join(os.tmpdir(), 'uploads'),
  limits: {
    fileSize: 200 * 1024 * 1024, // 200 MB max file size — adjust as needed
  },
  fileFilter: (req, file, cb) => {
    // accept only .tar.gz or .tgz
    const name = file.originalname.toLowerCase();
    if (name.endsWith('.tar.gz') || name.endsWith('.tgz')) return cb(null, true);
    cb(new Error('Only .tar.gz / .tgz files are allowed'));
  }
});

// Utility: safe extraction check to prevent path traversal
function isPathInside(parent, child) {
  const relative = path.relative(parent, child);
  return !!relative && !relative.startsWith('..') && !path.isAbsolute(relative);
}

// Extract tar.gz into destinationDir safely
async function safeExtractTarGz(archivePath, destinationDir) {
  await fs.ensureDir(destinationDir);

  // Use tar.t to list and validate first (optional extra safety)
  await tar.t({
    file: archivePath,
    onentry: entry => {
      const entryPath = entry.path;
      // Disallow absolute paths
      if (path.isAbsolute(entryPath)) {
        throw new Error(`Invalid entry (absolute path): ${entryPath}`);
      }
      // Disallow parent traversal segments
      const normalized = path.normalize(entryPath);
      if (normalized.startsWith('..') || normalized.includes(`..${path.sep}`)) {
        throw new Error(`Invalid entry (path traversal): ${entryPath}`);
      }
      // Optionally limit individual file sizes by reading header size (entry.size)
      // if (entry.size > 50 * 1024 * 1024) throw new Error('Entry too large');
    }
  });

  // If validation passed, extract
  await tar.x({
    file: archivePath,
    cwd: destinationDir,
    strip: 0, // keep structure; set >0 to strip leading parts
    // onentry: entry => { /* can do additional checks for each entry */ }
  });

  return true;
}

// Helper: walk directory and return file list (simple)
async function listFilesRecursive(dir) {
  const results = [];
  async function walk(current) {
    const entries = await fs.readdir(current, { withFileTypes: true });
    for (const entry of entries) {
      const full = path.join(current, entry.name);
      const rel = path.relative(dir, full);
      if (entry.isDirectory()) {
        await walk(full);
      } else if (entry.isFile()) {
        const stat = await fs.stat(full);
        results.push({
          path: rel.replace(/\\/g, '/'),
          size: stat.size,
          mtime: stat.mtime,
          mime: mime.lookup(full) || 'application/octet-stream'
        });
      }
    }
  }
  await walk(dir);
  return results;
}

// POST upload & extract
router.post('/upload/targz', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) return res.status(400).json({ error: 'No file uploaded' });

    const uploadId = uuidv4();
    const destinationBase = path.join(os.tmpdir(), 'targz_extracts');
    const destDir = path.join(destinationBase, uploadId);

    // Ensure dest directory exists and is empty
    await fs.ensureDir(destDir);

    // Path to uploaded temp file (multer)
    const archivePath = req.file.path;

    // Validate & extract safely
    try {
      await safeExtractTarGz(archivePath, destDir);
    } catch (err) {
      // Clean up
      await fs.remove(destDir);
      await fs.remove(archivePath);
      console.error('Extract error:', err);
      return res.status(400).json({ error: 'Invalid archive or extraction error', details: err.message });
    }

    // Remove uploaded archive to save space
    await fs.remove(archivePath);

    // List files and return uploadId
    const files = await listFilesRecursive(destDir);

    // Optionally persist upload metadata to DB here (uploader, expiry, etc.)
    res.json({ success: true, uploadId, files });
  } catch (err) {
    console.error('Upload error:', err);
    res.status(500).json({ error: 'Server error', details: err.message });
  }
});

// GET list of files for an upload
router.get('/upload/:id/list', async (req, res) => {
  try {
    const uploadId = req.params.id;
    const destinationBase = path.join(os.tmpdir(), 'targz_extracts');
    const destDir = path.join(destinationBase, uploadId);

    if (!await fs.pathExists(destDir)) return res.status(404).json({ error: 'Upload not found' });

    const files = await listFilesRecursive(destDir);
    res.json({ uploadId, files });
  } catch (err) {
    console.error('List error:', err);
    res.status(500).json({ error: 'Server error', details: err.message });
  }
});

// Download a file. Use wildcard route to allow paths
router.get('/upload/:id/file/*', async (req, res) => {
  try {
    const uploadId = req.params.id;
    const filePath = req.params[0]; // wildcard capture
    const destinationBase = path.join(os.tmpdir(), 'targz_extracts');
    const destDir = path.join(destinationBase, uploadId);

    if (!await fs.pathExists(destDir)) return res.status(404).json({ error: 'Upload not found' });

    // Resolve full path and check inside destDir
    const fullPath = path.join(destDir, filePath);
    const normalizedFull = path.normalize(fullPath);

    // Prevent path traversal
    if (!normalizedFull.startsWith(path.normalize(destDir + path.sep)) && normalizedFull !== path.normalize(destDir)) {
      return res.status(400).json({ error: 'Invalid file path' });
    }

    if (!await fs.pathExists(normalizedFull)) return res.status(404).json({ error: 'File not found' });

    // Stream file with correct content-type
    const mimeType = mime.lookup(normalizedFull) || 'application/octet-stream';
    res.setHeader('Content-Type', mimeType);
    res.setHeader('Content-Disposition', `attachment; filename="${path.basename(normalizedFull)}"`);

    const stream = fs.createReadStream(normalizedFull);
    stream.pipe(res);
  } catch (err) {
    console.error('Download error:', err);
    res.status(500).json({ error: 'Server error', details: err.message });
  }
});

module.exports = router;


Mount the router in your main server file (e.g. server.js or index.js):

const express = require('express');
const targzRouter = require('./routes/targzUpload');
const app = express();

// ... other middlewares
app.use('/api', targzRouter);

const port = process.env.PORT || 4000;
app.listen(port, () => console.log('Server running on', port));

Frontend React Component: UploadTarGz.jsx

This component provides drag/drop or file selection, uploads to /api/upload/targz, shows upload progress, lists extracted files, and provides download links.

// frontend/src/components/UploadTarGz.jsx
import React, { useState } from 'react';
import axios from 'axios';

export default function UploadTarGz() {
  const [file, setFile] = useState(null);
  const [uploadId, setUploadId] = useState(null);
  const [files, setFiles] = useState([]);
  const [progress, setProgress] = useState(0);
  const [status, setStatus] = useState('');

  function onFileChange(e) {
    setFile(e.target.files[0]);
    setStatus('');
    setProgress(0);
  }

  async function upload() {
    if (!file) return alert('Choose a .tar.gz file first');
    const form = new FormData();
    form.append('file', file);

    try {
      setStatus('Uploading...');
      const res = await axios.post('/api/upload/targz', form, {
        headers: { 'Content-Type': 'multipart/form-data' },
        onUploadProgress: progressEvent => {
          const pct = Math.round((progressEvent.loaded * 100) / progressEvent.total);
          setProgress(pct);
        }
      });

      if (res.data && res.data.success) {
        setStatus('Extracted successfully');
        setUploadId(res.data.uploadId);
        setFiles(res.data.files || []);
      } else {
        setStatus('Upload or extract failed');
      }
    } catch (err) {
      console.error(err);
      setStatus('Error: ' + (err.response?.data?.error || err.message));
    }
  }

  async function refreshList() {
    if (!uploadId) return;
    try {
      const res = await axios.get(`/api/upload/${uploadId}/list`);
      setFiles(res.data.files || []);
    } catch (err) {
      console.error(err);
      setStatus('Failed to refresh list');
    }
  }

  return (
    <div className="p-4 bg-white rounded shadow">
      <h3 className="font-semibold">Upload .tar.gz</h3>

      <input type="file" accept=".tar.gz,.tgz" onChange={onFileChange} />
      <div className="mt-2">
        <button onClick={upload} className="px-3 py-2 bg-blue-600 text-white rounded">Upload & Extract</button>
        <button onClick={refreshList} className="ml-2 px-3 py-2 bg-gray-200 rounded">Refresh List</button>
      </div>

      {progress > 0 && <div className="mt-2">Progress: {progress}%</div>}
      {status && <div className="mt-2 text-sm">{status}</div>}

      {files.length > 0 && (
        <div className="mt-4">
          <h4 className="font-semibold">Extracted Files</h4>
          <ul>
            {files.map((f, idx) => (
              <li key={idx} className="py-1">
                <a href={`/api/upload/${uploadId}/file/${encodeURIComponent(f.path)}`} target="_blank" rel="noopener noreferrer">
                  {f.path}
                </a>
                <span className="text-xs text-gray-500 ml-2">({(f.size/1024).toFixed(1)} KB)</span>
              </li>
            ))}
          </ul>
        </div>
      )}
    </div>
  );
}


Mount this component in your app where desired.

Extra: Serve and clean up old uploads

Extracts are stored in OS temp dir under targz_extracts/<uuid>. You should:

Periodically delete old uploads (cron job or cleanup worker). Example: remove directories older than 24 hours.

Optionally store metadata in DB to manage expiry, owner, and permissions.

Example cleanup script (run as cron):

// backend/cleanupOldUploads.js
const fs = require('fs-extra');
const path = require('path');
const os = require('os');

async function cleanup(days = 1) {
  const base = path.join(os.tmpdir(), 'targz_extracts');
  const entries = await fs.readdir(base).catch(()=>[]);
  const now = Date.now();
  for (const e of entries) {
    const full = path.join(base, e);
    const stat = await fs.stat(full).catch(()=>null);
    if (!stat) continue;
    const ageDays = (now - stat.mtimeMs) / (1000*60*60*24);
    if (ageDays > days) {
      console.log('Removing old upload', full);
      await fs.remove(full);
    }
  }
}

cleanup(1).then(()=>console.log('Cleanup done')).catch(console.error);

Security & Hardening (must read)

Path traversal — handled via validation on entries and final path checks. Do not remove these checks.

File size limits — multer limit and optional per-entry limit (you can inspect entry.size in tar listing).

Virus scanning — strongly recommended. Use an AV scanner (ClamAV) or cloud scanning API for uploaded content before making it available.

Permissions — run extraction under a non-privileged user, don't make extracts executable, and don't auto-run any scripts inside archives.

Resource limits — extraction can use CPU and disk. Monitor usage and restrict maximum concurrent extractions.

Authentication & authorization — if uploads are user-specific, enforce auth so users can only download their own extracted files.

HTTPS — secure your endpoints with TLS.

Summary / Next steps

Add the backend router file and mount it under /api (or your prefered path).

Add the React UploadTarGz component to your frontend.

Install the npm dependencies.

Add a periodic cleanup job and (ideally) an AV scanner.

Consider storing upload metadata in DB with owner user id and expiry.

If you want, I can: